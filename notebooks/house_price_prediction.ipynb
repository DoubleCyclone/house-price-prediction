{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvcLTEJh1/6L978KhsTFY6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoubleCyclone/house-price-prediction/blob/main/notebooks/house_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will be working with the \"**House Prices - Advanced Regression Techniques**\" dataset today to perform\n",
        "*   Exploratory Data Analysis\n",
        "*   Data Preprocessing\n",
        "*   Feature Engineering\n",
        "*   Model Building\n",
        "*   Evaluation\n",
        "*   and Visualisation\n",
        "\n",
        "First things first, I am going to mount google drive so that I can upload the dataset there and easily access it from the notebook.\n",
        "\n",
        "The dataset (and the competition) is at [Kaggle Competition/Dataset Link](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview)"
      ],
      "metadata": {
        "id": "raXe0IoNFeNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount the Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YLtSFPpKF_h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's import the other dependencies as well\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "jICfVFhTjH5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I will read the train.csv which is the training dataset and display a small portion of it."
      ],
      "metadata": {
        "id": "DgOPF8xYQlKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and test datasets, examine their shapes and contents\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/Colab_Materials/House_Price_Estimation/train.csv')\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/Colab_Materials/House_Price_Estimation/test.csv')\n",
        "# I will drop the ID columns as they are not used for training models\n",
        "data_train = data_train.drop('Id', axis=1)\n",
        "data_test = data_test.drop('Id', axis=1)\n",
        "\n",
        "print(f\"Shape of the train dataset = {data_train.shape}\")\n",
        "data_train.head()"
      ],
      "metadata": {
        "id": "nhLmpGMNQt9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of the test dataset = {data_test.shape}\")\n",
        "data_test.head()"
      ],
      "metadata": {
        "id": "DiEKeB8QQuv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like there are almost an equal amount of data in both datasets. There is also one more column in the train dataset called **SalePrice** is the sale price which will be the labels the model will learn from in this case. How about getting an idea of its distribution in the dataset?"
      ],
      "metadata": {
        "id": "2PqEfOgbe3Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the pandas.describe method to automatically generate valuable information about the dataset (only for a numerical variable in this case)\n",
        "print(data_train['SalePrice'].describe())\n",
        "\n",
        "# Plot the distribution of the SalePrice column\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.distplot(data_train['SalePrice'], color='g', bins=100, hist_kws={'alpha': 0.4});"
      ],
      "metadata": {
        "id": "ZFK1J-VHi9qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking at the output of the pandas.describe function and the graph, we can see that most of the Sale Prices reside at around 180000 and the standard deviation is quite low. Meaning that the data has low variability. How do I decide if the standard deviation is low or not? Firstly, I calculate the range of the data which is **max - min**. In this case **755000 - 34900 = 720100**. If the standard deviation is close to the range, I can say that the variability is high but in our case, standard deviation is approximately 10x lesser than the range which lets us conclude that the standard deviation, thus the variability in Sale Prices is low. <br><br>\n",
        "Now let's see what type of data is stored in the training dataset."
      ],
      "metadata": {
        "id": "7hY70rueoidx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the list of unique data types\n",
        "list(set(data_train.dtypes.tolist()))"
      ],
      "metadata": {
        "id": "d-1rtxn2xDZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's store the numerical data in a new DataFrame so that we can use it easily."
      ],
      "metadata": {
        "id": "Gs102umTyHfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame for numerical data only\n",
        "train_num = data_train.select_dtypes(include = ['float64', 'int64'])\n",
        "train_num.head()"
      ],
      "metadata": {
        "id": "YCHB0s7yyUgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While at that, let's plot the distributions of all these numerical features at the same time."
      ],
      "metadata": {
        "id": "qXf_qVPPyn7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
      ],
      "metadata": {
        "id": "CmC5qyKdyusB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}